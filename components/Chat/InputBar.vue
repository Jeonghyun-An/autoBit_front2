<template>
  <div class="px-3 py-2">
    <div class="max-w-5xl mx-auto">
      <!-- ë‹µë³€ ëª¨ë“œ ì„ íƒ ë²„íŠ¼ (Textarea ìœ„ì— ë°°ì¹˜) -->
      <div class="mb-2 flex items-center gap-2">
        <span class="text-xs text-zinc-500 font-medium">ë‹µë³€ ëª¨ë“œ:</span>
        <div
          class="inline-flex rounded-lg border border-slate-300 bg-white overflow-hidden"
        >
          <button
            type="button"
            :class="[
              'px-4 py-1.5 text-sm font-medium transition-colors',
              responseType === 'short'
                ? 'bg-slate-900 text-white'
                : 'bg-white text-slate-700 hover:bg-slate-100',
            ]"
            @click="responseType = 'short'"
          >
            ë‹¨ë¬¸í˜•
          </button>
          <button
            type="button"
            :class="[
              'px-4 py-1.5 text-sm font-medium transition-colors border-l border-slate-300',
              responseType === 'long'
                ? 'bg-slate-900 text-white'
                : 'bg-white text-slate-700 hover:bg-slate-100',
            ]"
            @click="responseType = 'long'"
          >
            ì¥ë¬¸í˜•
          </button>
        </div>
        <span class="text-xs text-zinc-500">
          {{
            responseType === "short"
              ? "(ê°„ê²°í•œ ë‹µë³€, ë¹ ë¥¸ ì‘ë‹µ)"
              : "(ìƒì„¸í•œ ë‹µë³€, ë” ë§ì€ ì»¨í…ìŠ¤íŠ¸)"
          }}
        </span>
      </div>

      <!-- ì±„íŒ…ì°½ê³¼ ë²„íŠ¼ì„ ë‚˜ë€íˆ ë°°ì¹˜ -->
      <div class="flex items-end gap-3">
        <!-- STT ë²„íŠ¼ -->
        <button
          type="button"
          :class="[
            'flex-shrink-0 w-12 h-12 rounded-full flex items-center justify-center transition-all',
            isListening
              ? 'bg-red-500 hover:bg-red-600 animate-pulse'
              : 'bg-zinc-200 hover:bg-zinc-300',
            (disabled || isTranscribing) && 'opacity-50 cursor-not-allowed',
          ]"
          :disabled="disabled || isTranscribing"
          :title="
            isListening ? 'ë…¹ìŒ ì¤‘ì§€ (Whisper)' : 'ìŒì„±ìœ¼ë¡œ ì…ë ¥ (Whisper)'
          "
          @click="toggleSpeechRecognition"
        >
          <Icon
            :name="isListening ? 'mdi:microphone' : 'mdi:microphone-outline'"
            :class="['w-6 h-6', isListening ? 'text-white' : 'text-zinc-700']"
          />
        </button>

        <!-- Textarea ì˜ì—­ -->
        <textarea
          ref="taRef"
          :class="[
            'flex-1 resize-none rounded-3xl text-black placeholder-zinc-500 p-3 pr-0 focus:outline-none focus:ring-2 focus:ring-slate-900 border border-slate-900',
            isOverflowing ? 'scrollbar-visible' : 'scrollbar-hidden',
          ]"
          rows="1"
          style="scrollbar-gutter: stable; line-height: 1.5rem"
          :placeholder="
            disabled
              ? 'ì±—ë´‡ ê°€ë™ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.'
              : isListening
              ? 'ë…¹ìŒ ì¤‘... (ë²„íŠ¼ í´ë¦­í•˜ì—¬ ì¤‘ì§€)'
              : isTranscribing
              ? 'ìŒì„± ë³€í™˜ ì¤‘...'
              : 'ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”. ë¬´ì—‡ì´ ê¶ê¸ˆí•œê°€ìš”?'
          "
          v-model="value"
          :disabled="disabled || isTranscribing"
          @keydown="onKeyDown"
        />

        <!-- ì „ì†¡ ë²„íŠ¼: í•­ìƒ í•˜ë‹¨ì— ê³ ì • -->
        <button
          type="button"
          class="flex-shrink-0 w-12 h-12 rounded-full bg-slate-900 hover:bg-slate-800 disabled:cursor-not-allowed flex items-center justify-center transition-colors"
          :disabled="disabled || !value.trim() || isTranscribing"
          title="ì „ì†¡ (Enter)"
          @click="submit"
        >
          <Icon name="mingcute:send-plane-fill" class="w-6 h-6 text-white" />
        </button>
      </div>

      <!-- ì•ˆë‚´ í…ìŠ¤íŠ¸ -->
      <div
        class="mt-2 flex items-center justify-between text-xs text-zinc-500 text-opacity-90"
      >
        <div class="flex items-center gap-2">
          <span>STT ì–¸ì–´:</span>
          <select
            v-model="sttLang"
            class="text-xs px-1.5 py-0.5 rounded border border-zinc-300 bg-zinc-100 text-zinc-500 focus:outline-none focus:ring-1 focus:ring-slate-900 hover:bg-white"
            :disabled="isListening || isTranscribing"
          >
            <option value="ko">í•œêµ­ì–´</option>
            <option value="en">English</option>
          </select>
          <span v-if="!microphoneSupported" class="text-zinc-500 text-xs">
            ë§ˆì´í¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤
          </span>
          <span v-else-if="isTranscribing" class="ttext-zinc-500 font-medium">
            ìŒì„± ë³€í™˜ ì¤‘...
          </span>
          <span v-else-if="sttError" class="text-zinc-500">
            {{ sttError }}
          </span>
        </div>
        <span>Enter: ì „ì†¡ Â· Shift+Enter: ì¤„ë°”ê¿ˆ</span>
      </div>
    </div>
  </div>
</template>

<script setup lang="ts">
import { ref, watch, onMounted, onBeforeUnmount } from "vue";

const emit = defineEmits<{
  (e: "send", text: string, responseType: "short" | "long"): void;
  (e: "height-changed", height: number): void;
}>();
const props = withDefaults(
  defineProps<{ disabled?: boolean; maxRows?: number }>(),
  { maxRows: 8 }
);

const value = ref("");
const taRef = ref<HTMLTextAreaElement | null>(null);
const responseType = ref<"short" | "long">("short");
const isOverflowing = ref(false);

// STT ê´€ë ¨ ìƒíƒœ (Whisper ê¸°ë°˜)
const isListening = ref(false);
const isTranscribing = ref(false);
const microphoneSupported = ref(true);
const sttLang = ref<string>("ko");
const sttError = ref("");

let mediaRecorder: MediaRecorder | null = null;
let audioChunks: Blob[] = [];

// ë‹µë³€ ëª¨ë“œ ë³€ê²½ ì‹œ localStorage ì €ì¥
watch(responseType, (newType) => {
  if (typeof window !== "undefined") {
    localStorage.setItem("rag_response_type", newType);
  }
});

// STT ì–¸ì–´ ë³€ê²½ ì‹œ localStorage ì €ì¥
watch(sttLang, (newLang) => {
  if (typeof window !== "undefined") {
    localStorage.setItem("rag_stt_lang", newLang);
  }
});

function autoresize() {
  const ta = taRef.value;
  if (!ta) return;

  ta.style.height = "0px";
  const lineHeight = parseFloat(getComputedStyle(ta).lineHeight || "24");
  const paddingY =
    parseFloat(getComputedStyle(ta).paddingTop || "0") +
    parseFloat(getComputedStyle(ta).paddingBottom || "0");
  const maxPx = props.maxRows * lineHeight + paddingY;

  isOverflowing.value = ta.scrollHeight > maxPx;
  ta.style.height = Math.min(ta.scrollHeight, maxPx) + "px";

  if (isOverflowing.value) {
    ta.style.overflowY = "auto";
  } else {
    ta.style.overflowY = "hidden";
  }

  emit("height-changed", ta.offsetHeight);
}

watch(value, () => autoresize());

function submit() {
  const v = value.value.trim();
  if (!v) return;

  // ìŒì„± ì¸ì‹ ì¤‘ì´ë©´ ì¤‘ì§€
  if (isListening.value) {
    stopRecording();
  }

  emit("send", v, responseType.value);
  value.value = "";
  autoresize();
}

function onKeyDown(e: KeyboardEvent) {
  if (e.key === "Enter" && !e.shiftKey) {
    e.preventDefault();
    if (!props.disabled && !isTranscribing.value) submit();
  }
}

function onResize() {
  autoresize();
}

function focus() {
  taRef.value?.focus();
}

defineExpose({
  focus,
});

// ==================== Whisper STT êµ¬í˜„ ====================

// STT API ì‘ë‹µ íƒ€ì… ì •ì˜
interface STTResponse {
  text: string;
  language: string;
  duration?: number;
  segments?: any[];
}

async function checkMicrophonePermission(): Promise<boolean> {
  if (typeof navigator === "undefined" || !navigator.mediaDevices) {
    microphoneSupported.value = false;
    return false;
  }

  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    stream.getTracks().forEach((track) => track.stop()); // ì¦‰ì‹œ í•´ì œ
    microphoneSupported.value = true;
    return true;
  } catch (error) {
    console.error("[STT] Microphone permission denied:", error);
    microphoneSupported.value = false;
    sttError.value = "ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤";
    return false;
  }
}

async function startRecording() {
  try {
    sttError.value = "";

    // ë§ˆì´í¬ ê¶Œí•œ í™•ì¸
    const hasPermission = await checkMicrophonePermission();
    if (!hasPermission) {
      alert(
        "ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”."
      );
      return;
    }

    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

    // MediaRecorder ìƒì„± (webm í˜•ì‹, ë¸Œë¼ìš°ì € í˜¸í™˜ì„± ë†’ìŒ)
    const mimeType = MediaRecorder.isTypeSupported("audio/webm;codecs=opus")
      ? "audio/webm;codecs=opus"
      : "audio/webm";

    mediaRecorder = new MediaRecorder(stream, { mimeType });
    audioChunks = [];

    mediaRecorder.ondataavailable = (event) => {
      if (event.data.size > 0) {
        audioChunks.push(event.data);
      }
    };

    mediaRecorder.onstop = async () => {
      console.log("[STT] Recording stopped, processing...");

      // ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
      stream.getTracks().forEach((track) => track.stop());

      // ì˜¤ë””ì˜¤ Blob ìƒì„±
      const audioBlob = new Blob(audioChunks, { type: mimeType });

      // Whisper APIë¡œ ì „ì†¡
      await transcribeAudio(audioBlob);
    };

    mediaRecorder.start();
    isListening.value = true;
    console.log("[STT] Recording started");
  } catch (error) {
    console.error("[STT] Failed to start recording:", error);
    sttError.value = "ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨";
    alert("ë…¹ìŒì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´í¬ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.");
  }
}

function stopRecording() {
  if (mediaRecorder && mediaRecorder.state !== "inactive") {
    mediaRecorder.stop();
    isListening.value = false;
    console.log("[STT] Stopping recording...");
  }
}

async function transcribeAudio(audioBlob: Blob) {
  isTranscribing.value = true;
  sttError.value = "";

  try {
    console.log(`[STT] Sending audio to Whisper API (${audioBlob.size} bytes)`);

    const formData = new FormData();
    formData.append("audio", audioBlob, "recording.webm");
    formData.append("language", sttLang.value); // ko ë˜ëŠ” en
    formData.append("use_nuclear_context", "true"); // ì›ìë ¥ ì „ë¬¸ ìš©ì–´ ì‚¬ìš©

    const response = await $fetch<any>("/rag/stt/transcribe", {
      method: "POST",
      body: formData,
      baseURL: "",
      responseType: "json",
    }).catch(async (e) => {
      // ì‘ë‹µì´ textë¡œ ì™”ì„ ê°€ëŠ¥ì„±ë„ ìˆì–´ ë””ë²„ê¹…ìš©ìœ¼ë¡œ ë³´ê°•
      throw e;
    });

    console.log("[STT] Response:", response); // ğŸ” ë””ë²„ê¹…

    // ì‘ë‹µ êµ¬ì¡° ê²€ì¦
    if (!response || typeof response !== "object") {
      throw new Error("Invalid response format");
    }

    const transcribedText = (response.text || "").trim();

    if (transcribedText) {
      // ê¸°ì¡´ í…ìŠ¤íŠ¸ì— ì¶”ê°€
      if (value.value.trim()) {
        value.value += " " + transcribedText;
      } else {
        value.value = transcribedText;
      }

      console.log("[STT] Transcribed:", transcribedText);
      autoresize();
    } else {
      console.warn("[STT] Empty transcription result");
      sttError.value = "ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤";
    }
  } catch (error: any) {
    console.error("[STT] Transcription failed:", error);
    sttError.value = "ìŒì„± ë³€í™˜ ì‹¤íŒ¨";

    // ì—ëŸ¬ ìƒì„¸ ë¡œê¹…
    console.error("[STT] Error details:", {
      message: error?.message,
      statusCode: error?.statusCode,
      data: error?.data,
    });

    if (error?.statusCode === 404) {
      alert(
        "STT APIë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\në°±ì—”ë“œì— stt_routerê°€ ë“±ë¡ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."
      );
    } else if (error?.statusCode === 503) {
      alert(
        "STT ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\nstt-whisper ì»¨í…Œì´ë„ˆê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”."
      );
    } else if (error?.statusCode === 504) {
      alert("ìŒì„± ë³€í™˜ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.");
    } else {
      alert(
        `ìŒì„± ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n${
          error?.message || "Unknown error"
        }`
      );
    }
  } finally {
    isTranscribing.value = false;
  }
}

function toggleSpeechRecognition() {
  if (props.disabled || isTranscribing.value) return;

  if (!microphoneSupported.value) {
    alert("ë§ˆì´í¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.");
    return;
  }

  if (isListening.value) {
    stopRecording();
  } else {
    startRecording();
  }
}

onMounted(() => {
  // localStorageì—ì„œ ì €ì¥ëœ ëª¨ë“œ ë³µì›
  if (typeof window !== "undefined") {
    const saved = localStorage.getItem("rag_response_type");
    if (saved === "short" || saved === "long") {
      responseType.value = saved;
    }

    // STT ì–¸ì–´ ë³µì›
    const savedSttLang = localStorage.getItem("rag_stt_lang");
    if (savedSttLang) {
      sttLang.value = savedSttLang;
    }
  }

  // ë§ˆì´í¬ ì§€ì› í™•ì¸
  if (typeof navigator !== "undefined" && navigator.mediaDevices) {
    microphoneSupported.value = true;
  } else {
    microphoneSupported.value = false;
  }

  autoresize();
  window.addEventListener("resize", onResize);
});

onBeforeUnmount(() => {
  window.removeEventListener("resize", onResize);

  // ë…¹ìŒ ì¤‘ì´ë©´ ì •ë¦¬
  if (isListening.value) {
    stopRecording();
  }
});
</script>

<style scoped>
/* ì˜¤ë²„í”Œë¡œìš° ì—†ì„ ë•Œ: ìŠ¤í¬ë¡¤ë°” ì™„ì „íˆ ìˆ¨ê¹€ */
.scrollbar-hidden {
  overflow-y: hidden;
  scrollbar-width: none;
}

.scrollbar-hidden::-webkit-scrollbar {
  width: 0;
  height: 0;
}

/* ì˜¤ë²„í”Œë¡œìš° ìˆì„ ë•Œ: ìŠ¤í¬ë¡¤ë°” í‘œì‹œ */
.scrollbar-visible {
  overflow-y: auto;
  scrollbar-width: thin;
  scrollbar-color: #d4d4d9 transparent;
}

.scrollbar-visible::-webkit-scrollbar {
  width: 8px;
}

.scrollbar-visible::-webkit-scrollbar-track {
  background: transparent;
}

.scrollbar-visible::-webkit-scrollbar-thumb {
  background: #d4d4d9;
  border-radius: 4px;
}

.scrollbar-visible::-webkit-scrollbar-thumb:hover {
  background: #a1a1aa;
}

.scrollbar-visible::-webkit-scrollbar-button {
  display: none;
  width: 0;
  height: 0;
}

/* ë§ˆì´í¬ ë²„íŠ¼ ì• ë‹ˆë©”ì´ì…˜ */
@keyframes pulse {
  0%,
  100% {
    opacity: 1;
  }
  50% {
    opacity: 0.7;
  }
}

.animate-pulse {
  animation: pulse 2s cubic-bezier(0.4, 0, 0.6, 1) infinite;
}
</style>
